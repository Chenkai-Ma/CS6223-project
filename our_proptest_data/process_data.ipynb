{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data format to make it compatible with OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonlines_load(fname: str):\n",
    "    with open(fname, 'r') as f:\n",
    "        return [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert api docs into json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the .txt files\n",
    "directory = \"api_docs\"\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        function_name = os.path.splitext(filename)[0]  # Get the function name (without .txt)\n",
    "        with open(os.path.join(directory, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "            api_doc = f.read().strip()  # Read the content of the file\n",
    "        # Append the data in the desired format\n",
    "        data.append({\"function_name\": function_name, \"api_doc\": api_doc})\n",
    "\n",
    "# Write the data to a JSON file, each line as a separate JSON object\n",
    "# with open(\"../our_proptest_data/api_docs.jsonl\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "#     for item in data:\n",
    "#         json_file.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory containing the .txt files\n",
    "directory = \"api_codes\"\n",
    "\n",
    "# Initialize an empty list to store the data\n",
    "data = []\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".py\"):\n",
    "        function_name = os.path.splitext(filename)[0]  # Get the function name (without .txt)\n",
    "        with open(os.path.join(directory, filename), \"r\", encoding=\"utf-8\") as f:\n",
    "            api_doc = f.read().strip()  # Read the content of the file\n",
    "        # Append the data in the desired format\n",
    "        data.append({\"function_name\": function_name, \"api_code\": api_doc})\n",
    "\n",
    "# Write the data to a JSON file, each line as a separate JSON object\n",
    "# with open(\"../our_proptest_data/api_codes.jsonl\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "#     for item in data:\n",
    "#         json_file.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_doc_data = jsonlines_load(\"api_docs.jsonl\")\n",
    "api_code_data = jsonlines_load(\"api_codes.jsonl\")\n",
    "api_doc_code_data = {}\n",
    "\n",
    "for i in range(len(api_doc_data)):\n",
    "    name = api_doc_data[i][\"function_name\"]\n",
    "    if name not in api_doc_code_data:\n",
    "        api_doc_code_data[name] = {}\n",
    "    api_doc_code_data[name].update(api_doc_data[i])\n",
    "\n",
    "for i in range(len(api_code_data)):\n",
    "    name = api_code_data[i][\"function_name\"]\n",
    "    if name not in api_doc_code_data:\n",
    "        api_doc_code_data[name] = {}\n",
    "    api_doc_code_data[name].update(api_code_data[i])\n",
    "\n",
    "api_doc_code_data = list(api_doc_code_data.values())\n",
    "\n",
    "# with open(f\"api_doc_code.jsonl\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "#     for item in api_doc_code_data:\n",
    "#         json_file.write(json.dumps(item)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_doc_code_data = jsonlines_load(\"api_doc_code.jsonl\")\n",
    "# api_code_data = jsonlines_load(\"api_codes.jsonl\")\n",
    "# api_doc_data = jsonlines_load(\"api_docs.jsonl\")\n",
    "\n",
    "# for i in range(len(api_doc_code_data)):\n",
    "#     for j in range(len(api_doc_data)):\n",
    "#         if api_doc_code_data[i]['function_name'] == api_doc_data[j]['function_name']:\n",
    "#             assert api_doc_code_data[i]['api_doc'] == api_doc_data[j]['api_doc']\n",
    "\n",
    "#     for j in range(len(api_code_data)):\n",
    "#         if api_doc_code_data[i]['function_name'] == api_code_data[j]['function_name']:\n",
    "#             assert api_doc_code_data[i]['api_code'] == api_code_data[j]['api_code']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert json format into txt format (property)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('code_only/output_jsonl/property/property_0_30_11-07-19-32.jsonl', 'r') as f:\n",
    "    output_dir = 'code_only/properties'\n",
    "    for line in f:\n",
    "        data = json.loads(line.strip())\n",
    "        function_name = data['function_name']\n",
    "        properties = data['properties'][0]\n",
    "\n",
    "        txt_file_name = function_name + '.txt'\n",
    "        txt_file_path = os.path.join(output_dir, txt_file_name)\n",
    "\n",
    "        # with open(txt_file_path, 'w') as txt_file:\n",
    "        #     txt_file.write(properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write json file into .py (pbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('code_only/output_jsonl/pbt/pbt_0_30_11-07-19-48.jsonl', 'r') as f:\n",
    "    output_dir = 'code_only/proptest'\n",
    "    for line in f:\n",
    "        data = json.loads(line.strip())\n",
    "        function_name = data['function_name']\n",
    "        pbt = data['pbt']\n",
    "        \n",
    "        function_dir = os.path.join(output_dir, function_name)\n",
    "        os.makedirs(function_dir, exist_ok=True)\n",
    "\n",
    "        for i, pbt_data in enumerate(pbt):\n",
    "            j = i+1\n",
    "            if pbt_data.startswith('```python\\n'):\n",
    "                pbt_data = pbt_data[len('```python\\n'):].strip()\n",
    "            if pbt_data.endswith('```'):\n",
    "                pbt_data = pbt_data[:-len('```')].strip()\n",
    "            txt_file_name = f'pbt_{j}.py'\n",
    "            txt_file_path = os.path.join(function_dir, txt_file_name)\n",
    "\n",
    "            # with open(txt_file_path, 'w') as txt_file:\n",
    "            #     txt_file.write(pbt_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write mutants in json format into .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single file\n",
    "with open('mutants/html.escape.jsonl', 'r') as f:\n",
    "    output_dir = 'our_proptest_data/mutants'\n",
    "    i = 1\n",
    "    for line in f:\n",
    "        data = json.loads(line.strip())\n",
    "        function_name = data['function_name']\n",
    "        mutant_data = data['mutants'][0]\n",
    "        \n",
    "        function_dir = os.path.join(output_dir, function_name)\n",
    "        os.makedirs(function_dir, exist_ok=True)\n",
    "\n",
    "        if mutant_data.startswith('```python\\n'):\n",
    "            mutant_data = mutant_data[len('```python\\n'):].strip()\n",
    "        if mutant_data.endswith('```'):\n",
    "            mutant_data = mutant_data[:-len('```')].strip()\n",
    "        txt_file_name = f'mutant_{i}.py'\n",
    "        txt_file_path = os.path.join(function_dir, txt_file_name)\n",
    "\n",
    "        # with open(txt_file_path, 'w') as txt_file:\n",
    "        #     txt_file.write(mutant_data)\n",
    "        \n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"doc_only/mutants/\"\n",
    "for filename in os.listdir(\"doc_only/output_jsonl/mutants\"):\n",
    "    if filename.endswith(\".jsonl\"):\n",
    "        data = jsonlines_load(\"doc_only/output_jsonl/mutants/\" + filename)\n",
    "        for i in range(len(data)):\n",
    "            function_name = data[i]['function_name']\n",
    "            mutant_data = data[i]['mutants'][0]\n",
    "\n",
    "            function_dir = os.path.join(output_dir, function_name)\n",
    "            os.makedirs(function_dir, exist_ok=True)\n",
    "\n",
    "            if mutant_data.startswith('```python\\n'):\n",
    "                mutant_data = mutant_data[len('```python\\n'):].strip()\n",
    "            if mutant_data.endswith('```'):\n",
    "                mutant_data = mutant_data[:-len('```')].strip()\n",
    "            txt_file_name = f'mutant_{i+1}.py'\n",
    "            txt_file_path = os.path.join(function_dir, txt_file_name)\n",
    "\n",
    "            # with open(txt_file_path, 'w') as txt_file:\n",
    "            #     txt_file.write(mutant_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate file for mutant generation in json format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A demo to show the file format. Better to convert the file format into json format automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "function_name = \"statistics.pstdev\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "properties = [\n",
    "    \"\"\"1. The output of `pstdev` should always be non-negative, as standard deviation cannot be negative.\"\"\",\n",
    "    \"\"\"2. If the input data set is empty, `pstdev` should raise a `StatisticsError`, indicating that at least one data point is required.\"\"\",\n",
    "    \"\"\"3. If the input data contains only one data point, the output of `pstdev` should be zero, since there is no variation in a single value.\"\"\",\n",
    "    \"\"\"4. The output of `pstdev` should be consistent with the output of `pstdev` when the input data is the same, regardless of the order of the data points.\"\"\",\n",
    "    # \"\"\"5. The median is invariant under the order of the input data; that is, sorting the data before finding the median should yield the same result as finding the median directly from the unsorted data.\"\"\",\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pbt_1 = \"\"\"\n",
    "@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1))\n",
    "def test_statistics_pstdev_non_negative_property(data):\n",
    "    result = pstdev(data)\n",
    "    assert result >= 0\n",
    "\"\"\".strip()\n",
    "\n",
    "pbt_2 = \"\"\"\n",
    "@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=0))\n",
    "def test_statistics_pstdev_empty_input_property(data):\n",
    "    if len(data) == 0:\n",
    "        try:\n",
    "            pstdev(data)\n",
    "            assert False, \"Expected StatisticsError for empty input\"\n",
    "        except StatisticsError:\n",
    "            pass\n",
    "\"\"\".strip()\n",
    "\n",
    "pbt_3 = \"\"\"\n",
    "@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1))\n",
    "def test_statistics_pstdev_single_value_property(data):\n",
    "    result = pstdev([data[0]])\n",
    "    assert result == 0\n",
    "\"\"\".strip()\n",
    "\n",
    "pbt_4 = \"\"\"\n",
    "@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=1))\n",
    "def test_statistics_pstdev_order_invariance_property(data):\n",
    "    result1 = pstdev(data)\n",
    "    result2 = pstdev(data[::-1])\n",
    "    assert result1 == result2\n",
    "\"\"\".strip()\n",
    "\n",
    "pbt_5 = \"\"\"\n",
    "\"\"\".strip()\n",
    "\n",
    "pbts = [\n",
    "        pbt_1, \n",
    "        pbt_2,\n",
    "        pbt_3,\n",
    "        pbt_4,\n",
    "        # pbt_5,\n",
    "        ]\n",
    "\n",
    "api_doc = \"\"\"statistics.pstdev(data, mu=None)\n",
    "Return the population standard deviation (the square root of the population variance). See pvariance() for arguments and other details.\n",
    "\n",
    ">>>\n",
    "pstdev([1.5, 2.5, 2.5, 2.75, 3.25, 4.75])\n",
    "0.986893273527251\n",
    "\"\"\".strip()\n",
    "\n",
    "to_save_test_property = {\n",
    "    \"function_name\":function_name,\n",
    "    \"properties\": properties,\n",
    "    \"pbt\": pbts,\n",
    "    'api_doc': api_doc\n",
    "}\n",
    "\n",
    "output_dir = 'sound_valid'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "test_file_name = f\"{function_name}.jsonl\"\n",
    "test_file_path = os.path.join(output_dir, test_file_name)\n",
    "\n",
    "with open(test_file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "    # for item in data:\n",
    "    json_file.write(json.dumps(to_save_test_property) + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
