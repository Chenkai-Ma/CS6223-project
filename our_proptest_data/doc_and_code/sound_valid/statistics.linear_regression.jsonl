{"function_name": "statistics.linear_regression", "properties": ["3. If both input lists have the same values (e.g., x = [1, 2, 3] and y = [1, 2, 3]), the slope should be equal to 1 and the intercept should be 0 (or undefined when proportional is true)."], "pbt": ["@given(st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=2, max_size=1000).filter(lambda lst: len(set(lst)) > 1), \n                st.lists(st.floats(allow_nan=False, allow_infinity=False), min_size=2, max_size=1000))\ndef test_constant_input_property(x, y):\n    constant_x = [5] * len(y)\n    try:\n        statistics.linear_regression(constant_x, y)\n        assert False, \"Expected StatisticsError for constant x\"\n    except StatisticsError:\n        pass"], "api_doc": "statistics.linear_regression(x, y, /, *, proportional=False)\nReturn the slope and intercept of simple linear regression parameters estimated using ordinary least squares. Simple linear regression describes the relationship between an independent variable x and a dependent variable y in terms of this linear function:\n\ny = slope * x + intercept + noise\n\nwhere slope and intercept are the regression parameters that are estimated, and noise represents the variability of the data that was not explained by the linear regression (it is equal to the difference between predicted and actual values of the dependent variable).\n\nBoth inputs must be of the same length (no less than two), and the independent variable x cannot be constant; otherwise a StatisticsError is raised.\n\nFor example, we can use the release dates of the Monty Python films to predict the cumulative number of Monty Python films that would have been produced by 2019 assuming that they had kept the pace.\n\n>>>\nyear = [1971, 1975, 1979, 1982, 1983]\nfilms_total = [1, 2, 3, 4, 5]\nslope, intercept = linear_regression(year, films_total)\nround(slope * 2019 + intercept)\n16\nIf proportional is true, the independent variable x and the dependent variable y are assumed to be directly proportional. The data is fit to a line passing through the origin. Since the intercept will always be 0.0, the underlying linear function simplifies to:\n\ny = slope * x + noise\n\nContinuing the example from correlation(), we look to see how well a model based on major planets can predict the orbital distances for dwarf planets:\n\n>>>\nmodel = linear_regression(period_squared, dist_cubed, proportional=True)\nslope = model.slope\n\n# Dwarf planets:   Pluto,  Eris,    Makemake, Haumea, Ceres\norbital_periods = [90_560, 204_199, 111_845, 103_410, 1_680]  # days\npredicted_dist = [math.cbrt(slope * (p * p)) for p in orbital_periods]\nlist(map(round, predicted_dist))\n[5912, 10166, 6806, 6459, 414]\n\n[5_906, 10_152, 6_796, 6_450, 414]  # actual distance in million km\n[5906, 10152, 6796, 6450, 414]\nAdded in version 3.10.\n\nChanged in version 3.11: Added support for proportional.", "api_code": "def linear_regression(x, y, /, *, proportional=False):\n    n = len(x)\n    if len(y) != n:\n        raise StatisticsError('linear regression requires that both inputs have same number of data points')\n    if n < 2:\n        raise StatisticsError('linear regression requires at least two data points')\n    if not proportional:\n        xbar = fsum(x) / n\n        ybar = fsum(y) / n\n        x = [xi - xbar for xi in x]  # List because used three times below\n        y = (yi - ybar for yi in y)  # Generator because only used once below\n    sxy = sumprod(x, y) + 0.0        # Add zero to coerce result to a float\n    sxx = sumprod(x, x)\n    try:\n        slope = sxy / sxx   # equivalent to:  covariance(x, y) / variance(x)\n    except ZeroDivisionError:\n        raise StatisticsError('x is constant')\n    intercept = 0.0 if proportional else ybar - slope * xbar\n    return LinearRegression(slope=slope, intercept=intercept)"}