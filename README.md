# CS6223-project

## Tentative Schedule

### Timeline

Suggested deadline to finish coding: **8 Nov**

Deadline to finish this project: **15 Nov**

Tentative page length: 5 or 6 pages.

### Tasks

| Name | Code                                                            | Paper                                       | Other |
| ---- | --------------------------------------------------------------- | ------------------------------------------- | ----- |
| mck  | Evaluation/post-processing                                      | code-related parts and common no-code parts |       |
| zx   | LLM prompting (in both methods and computing property coverage) | code-related parts and common no-code parts |       |

## Related Material

- [Paper: *Can Large Language Models Write Good Property-Based Tests?*](Vikram%20et%20al.%20-%202024%20-%20Can%20Large%20Language%20Models%20Write%20Good%20Property-Base.pdf))
- [Project proposal](CS6223-Proposal-Property_Based_Testing_with_LLMs.pdf)
- [Project planning](https://docs.google.com/document/d/1ly9GCxzbsbM736tBZ5D-mHyUhjS1L6Jd63JEcierU1o/edit#heading=h.r5acg7cz2fk7)
- [Hypothesis](https://hypothesis.readthedocs.io/en/latest/)

## (Re)implementation

### Method

- The actual prompt for single stage prompting is in [`prompts.py`](proptest_ai_data/prompts.py): `SYSTEM_PROMPT + PBT_PROMPT_TEMPLATE (filled with API docs) + OUTPUT_FORMAT_TEMPLATE (example)`
- The actual prompt for two stage prompting is in [`prompts.py`](proptest_ai_data/prompts.py): `SYSTEM_PROMPT + PROPERTIES_PROMPT (filled with API docs) + PBT_PROPERTIES_PROMPT + (*)OUTPUT_FORMAT_TEMPLATE`
- What they have in common: they both generate one PBT for one invocation.
- **Their difference**: the PBT generated by single stage prompting ([example](proptest_ai_data/proptests/gpt-4-final/datetime.date.isocalendar/single_stage/pbt_1.py)) has only one test function which tests multiple properties at once; the PBT generated by two stage prompting ([example](proptest_ai_data/proptests/gpt-4-final/datetime.date.isocalendar/two_stage/pbt_1.py)) has multiple testing functions, and each one test one property.

### Evaluation: Property Coverage

- Actual prompt to extract properties p1 for a API method f: reuse prompts in [`prompts.py`](proptest_ai_data/prompts.py) for two stage prompting.
- The code to generate five property mutants for each property pi is in [`prompts.py`](proptest_ai_data/prompts.py): `(Maybe)SYSTEM_PROMPT + MUTANTS_PROMPT (filled with api docs and one property)`

## Ideas for the project

### General

- **[11 Oct]** Follow the file structure and naming conventions of the origianl project, e.g., each test function should start with "test_", and each PBT python file should be named "pbt_*.py".

### Method

- **[17 Oct]** Source code for API: Finding fully self-contained codes is rather impractical, and it is reasonable to assume LLMs know how to call some basic python functions. So we may **prioritize "doc + code" (code is used to complement or enhance doc) over "code alone" (it may perform poorly), and compare "doc + code" mainly to "doc alone".** One practical advantage of "doc + code" is that API docs are often written in the API source codes as comments, which makes it easier to construct prompts.
- **[11 Oct]** Use the same properties to generate original PBTs (e.g., in double-stage prompting) and property mutants to prevent mismatches.

### Evaluating PTBs

- **[11 Oct]** Property coverage: Instead of generating property mutants from original API, then substitude original PTB to get mutated PTB, we may **directly prompt LLM to generate mutated test functions from original test functions (along with their properties).** This helps to solve some intricacies of constructing mutated PTB (see your notes), simplifies the workflow, and could also be **one contribution**. Mutated test functions should be filtered for soundness, and aim for assertion errors.

### Experiment Setup

- **[17 Oct]** API to test [(Google doc)](https://docs.google.com/spreadsheets/d/1ho1ij9dSY98MuzCt7yKXHBuz76prcS5Z1I_kI3RQznE/edit?gid=0#gid=0): 30 in total (16 original + 14 new). The source code for each API should be at least moderately self-contained, i.e., have some basic logic, and should be rather simple/short. Docs are stored in folder "api_docs" as .txt files and named according to the url of the API, e.g. "[datetime.date.isocalendar](https://docs.python.org/3/library/datetime.html#datetime.date.isocalendar)" (this naming is a little different from the original paper), while the content are directly copied from the urls. Codes are stored in folder "api_codes" as .py files and named similarly, and the content are just the one function for the API (no other stuff like imports). Specifically, for each code, I removed the docstring because it is similar to the docs, and we want to separate codes from docs; I also slightly adjusted some identation; 
